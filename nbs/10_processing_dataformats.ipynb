{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data formats \n",
    "\n",
    "... an overview of formats that you might come across and when you might use them. \n",
    "\n",
    "## Text-based formats\n",
    "### Tabular text files: csv, tsv, txt\n",
    "\n",
    "**What to use:** `pandas` (`pd.read_csv()`)\n",
    "\n",
    "I'd say, in general the most common file format you might encounter. Also, potentially messy since there is no true schema to it (there are actually many). Luckily, pandas has a pretty great `read_csv()` Function that can handle pretty much any variant you might come across (it's actually so versatile that it has about 250 arguments you can specify!!!).\n",
    "\n",
    "We cannot possbibly cover all aspects, but some of the more common arguments (at least for me) are:\n",
    "- specifying the seperator (`sep=`)\n",
    "- split at any kind of whitespace (`delim_whitespace=True`)\n",
    "- specifying if there's no header (`header=None`)\n",
    "- giving column names (`names=[\"Col1\",\"Col2\",...]`; if the file has no colnames yet don't forget to specify `header=None`, too)\n",
    "- use a columns to set the index (`index_col='myIndexCol'`)\n",
    "- specify which value should be considered missing/ NaN (`na_values=[-9999, 'na', 'none']`) - this can also be done per-column if you specify a dictionary for your columns with the individual NaN-values to filter\n",
    "- skipping rows (`skiprows=5`)\n",
    "- convert date columns to an actual date type during import (`parse_dates=True` or `parse_dates=['DateCol1', 'DateCol2']`) - you can also specify a custom data/time parser function if pandas has trouble detecting the correct format\n",
    "\n",
    "> **TODO**: Look for a complex csv file that we already have in the repo...\n",
    ">\n",
    "\n",
    "**Tip:** Since formats are so variable it's often a good idea to peak into the first 10 to 100 lines of a file. A fast and easy way to do this in Jupyter is to issue a bash command inline like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head -n 10 data/testfile.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A small example:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv('data/testfile.csv', index_col=['ID'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XML\n",
    "\n",
    "**What to use:** `cElementTree` (or: `lxml`)\n",
    "\n",
    "The Extensible Markup Language (XML) usually encodes a document or data structure. It is organized tree-like thus supports a hierarchy. Usually a schema is defined that defines what a given XML document can contain (like a database schema). The basic building blocks to encapsule data are elements and attributes. You can have elements that enclose text (`<myelement>text</myelement>`) or elements without text (`<myelement />`). Often, you also have attributes in an element (`<myelement attribute1=\"A\" another_attr=\"2\"/>`).\n",
    "\n",
    "A nested XML structure might look like this:\n",
    "\n",
    "```\n",
    "<person sex=\"female\">\n",
    "  <firstname>Anna</firstname>\n",
    "  <lastname>Smith</lastname>\n",
    "</person>\n",
    "```\n",
    "A small example with data we will use in the Deep Learning lessons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import xml.etree.cElementTree as ET\n",
    "\n",
    "# get xml files in dir and return first one from generator using next()\n",
    "file_path = next(Path('/data/ifu/summerschool/original.datasets/ImageCLEF_2013/train').glob('*.xml'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, if we do not have a clear picture what is actually in the file it's a good idea to print it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<Image>\n",
      "  <FileName>6145.jpg</FileName>\n",
      "  <IndividualPlantId>3040</IndividualPlantId>\n",
      "  <Date>22/06/09</Date>\n",
      "  <Locality>France - Paris</Locality>\n",
      "  <GPSLocality>\n",
      "    <Longitude>2.350986</Longitude>\n",
      "    <Latitude>48.856667</Latitude>\n",
      "  </GPSLocality>\n",
      "  <Author>Annick Larbouillat</Author>\n",
      "  <Organization>Tela Botanica</Organization>\n",
      "  <Type>SheetAsBackground</Type>\n",
      "  <Content>Leaf</Content>\n",
      "  <ClassId>Quercus ilex</ClassId>\n",
      "  <Taxon>\n",
      "    <Regnum>Plantae</Regnum>\n",
      "    <Class>Equisetopsida C. Agardh</Class>\n",
      "    <Subclass>Magnoliidae NovÃ¡k ex Takht.</Subclass>\n",
      "    <Superorder>Rosanae Takht.</Superorder>\n",
      "    <Order>Fagales Engl.</Order>\n",
      "    <Family>Fagaceae Dumort.</Family>\n",
      "    <Genus>Quercus L.</Genus>\n",
      "    <Species>Quercus ilex L.</Species>\n",
      "  </Taxon>\n",
      "  <VernacularNames>Holm oak</VernacularNames>\n",
      "  <Year>ImageCLEF2011</Year>\n",
      "  <IndividualPlantId2012>812</IndividualPlantId2012>\n",
      "  <ImageID2012>8761.jpg</ImageID2012>\n",
      "</Image>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Note that we can use python variables in a bash command with the curly brackets !!!\n",
    "! cat {file_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see this schema apparently does not use any attributes, just elements..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Element 'Image' at 0x7fb601c8bb88>\n"
     ]
    }
   ],
   "source": [
    "# parse the entire file\n",
    "xml = ET.parse(file_path)\n",
    "\n",
    "# get the document root element\n",
    "root = xml.getroot()\n",
    "\n",
    "print(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot do a full XML tutorial here, but you can either iterate through elements or you can search for a specific one.\n",
    "The following code searches for the first occurance of the subelement Family and return the text enclosed by the element\n",
    "(if it had an attribute we could query it using `.attrib['attributeName']`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fagaceae Dumort.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root.find('./Taxon/Family').text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Note:** \n",
    "- Using the package `xmltodict` (not shown) we can also read in a XML file and convert it to a nested python dictionary. We then could pass it on and convert it into a JSON structure (which basically is a nested dictionary).\n",
    "- If our file had many entries of *Image*, one would iterate over them like this:\n",
    "\n",
    "```python\n",
    "for child in root:\n",
    "    print(child.tag, child.attrib, child.text)\n",
    "```\n",
    "- More on using ElementTree [here](https://docs.python.org/3/library/xml.etree.elementtree.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON\n",
    "\n",
    "JavaScript Object Notation (JSON) was inspired by a subset of the JavaScript programming language dealing with object literal syntax but nowadays has its own standard. JSON supports primitive types, like strings and numbers, as well as nested lists and objects.\n",
    "\n",
    "An example looks like this:\n",
    "```JSON\n",
    "{\n",
    "    \"firstName\": \"Jane\",\n",
    "    \"lastName\": \"Doe\",\n",
    "    \"hobbies\": [\"running\", \"sky diving\", \"singing\"],\n",
    "    \"age\": 35,\n",
    "    \"children\": [\n",
    "        {\n",
    "            \"firstName\": \"Alice\",\n",
    "            \"age\": 6\n",
    "        },\n",
    "        {\n",
    "            \"firstName\": \"Bob\",\n",
    "            \"age\": 8\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can read in a JSON file like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# reading a json file\n",
    "with open(\"data_file.json\", \"r\") as read_file:\n",
    "    data = json.load(read_file)\n",
    "\n",
    "# dumping a json file\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you already have a JSON structure in a string (because you fulled it in from the web etc.):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'researcher': {'name': 'Ford Prefect',\n",
       "  'species': 'Betelgeusian',\n",
       "  'relatives': [{'name': 'Zaphod Beeblebrox', 'species': 'Betelgeusian'}]}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json_string = \"\"\"\n",
    "{\n",
    "    \"researcher\": {\n",
    "        \"name\": \"Ford Prefect\",\n",
    "        \"species\": \"Betelgeusian\",\n",
    "        \"relatives\": [\n",
    "            {\n",
    "                \"name\": \"Zaphod Beeblebrox\",\n",
    "                \"species\": \"Betelgeusian\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "data = json.loads(json_string)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** better example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary formats\n",
    "### Excel ðŸ¤¨\n",
    "\n",
    "Ok, **you really should be using csv files instead**. However, if you need to import Excel files pandas can do it (if you also install `xlrd`)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pd.read_excel(open('tmp.xlsx', 'rb'), sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pkl\n",
    "### netcdf3/4\n",
    "### sql\n",
    "### hdf5/ h5\n",
    "### npy/ npz\n",
    "## Geographic data\n",
    "### Shapefiles\n",
    "### Geotiffs\n",
    "## Other\n",
    "### parquet\n",
    "### feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
